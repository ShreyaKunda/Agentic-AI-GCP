{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "print(\"‚è≥ Installing required libraries...\")\n",
        "!pip install google-genai pydantic rich python-docx pypandoc --quiet\n",
        "print(\"‚úÖ Installation complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLzWSql1q544",
        "outputId": "2ccb2f3b-55e5-4a02-e482-628ed9d6a54a"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚è≥ Installing required libraries...\n",
            "‚úÖ Installation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import json\n",
        "import traceback\n",
        "import os\n",
        "import re\n",
        "import requests\n",
        "from google.colab import files\n",
        "\n",
        "import datetime\n",
        "\n",
        "import pypandoc\n",
        "\n",
        "\n",
        "\n",
        "import google.genai as genai\n",
        "\n",
        "from google.genai.types import Tool\n",
        "from google.genai import types\n",
        "\n",
        "\n",
        "from typing import Any, List, Dict, Optional\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from rich import print as rich_print\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "from typing import Any, Dict, Optional\n",
        "from pydantic import BaseModel\n",
        "from rich import print as rich_print\n",
        "\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "enItqU9sruwK"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PlanStep(BaseModel):\n",
        "    step_id: int\n",
        "    agent_name: str\n",
        "    description: str\n",
        "\n",
        "class ExecutionPlan(BaseModel):\n",
        "    query: str\n",
        "    steps: List[PlanStep]\n",
        "\n",
        "class PlanningAgent(BaseModel):\n",
        "    client: Any\n",
        "    model_name: str\n",
        "    debug: bool = False\n",
        "\n",
        "    class Config:\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "    def create_plan(self, query: str) -> ExecutionPlan:\n",
        "        \"\"\"Creates a static execution plan for research.\"\"\"\n",
        "        if self.debug:\n",
        "            rich_print(\"ü§î [bold cyan]Planning Phase:[/bold cyan] Creating execution plan...\")\n",
        "\n",
        "        steps = [\n",
        "            PlanStep(step_id=1, agent_name=\"QueryAnalysisAgent\", description=\"Analyze the user query to identify key research topics.\"),\n",
        "            PlanStep(step_id=2, agent_name=\"DataGatherAgent\", description=\"Conduct web searches on the identified topics using Google Search.\"),\n",
        "            PlanStep(step_id=3, agent_name=\"ReportAgent\", description=\"Synthesize search results into a comprehensive analysis report with citations.\"),\n",
        "        ]\n",
        "\n",
        "        plan = ExecutionPlan(query=query, steps=steps)\n",
        "\n",
        "        if self.debug:\n",
        "            rich_print(f\"‚úÖ [bold cyan]Plan Created:[/bold cyan] {len(steps)} steps defined.\")\n",
        "\n",
        "        return plan"
      ],
      "metadata": {
        "id": "uePRgD-Ps7vg"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QueryEntities(BaseModel):\n",
        "    research_topics: List[str] = Field(description=\"A list of key technical topics and concepts to research based on the user's query.\")\n",
        "    main_subject: str = Field(description=\"The primary subject of the analysis, e.g., 'Aircraft Routers'.\")\n",
        "\n",
        "class QueryAnalysisAgent(BaseModel):\n",
        "    client: Any\n",
        "    model_name: str\n",
        "    debug: bool = False\n",
        "\n",
        "    class Config:\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "    def analyze(self, query: str) -> Dict:\n",
        "        \"\"\"Extracts key research topics from the user's query using the LLM.\"\"\"\n",
        "        if self.debug:\n",
        "            rich_print(f\"üîé [bold yellow]Query Analysis Phase:[/bold yellow] Analyzing query: '{query}'\")\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        From the following user query, extract the key technical topics that need to be researched to provide a comprehensive answer.\n",
        "        Also, identify the main subject or application area.\n",
        "\n",
        "        User Query: \"{query}\"\n",
        "\n",
        "        Provide the output as a valid JSON object with two keys: \"research_topics\" (a list of strings) and \"main_subject\" (a string).\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.client.models.generate_content(\n",
        "                model=self.model_name,\n",
        "                contents=prompt,\n",
        "            )\n",
        "\n",
        "            llm_output = response.text\n",
        "\n",
        "            # **Extract JSON using regex:**\n",
        "            match = re.search(r\"\\{.*\\}\", llm_output, re.DOTALL)  # Find JSON object\n",
        "            if match:\n",
        "                json_string = match.group(0)  # Extract the matched JSON string\n",
        "                print(\"Extracted JSON:\", json_string) # Debugging\n",
        "                try:\n",
        "                  entities = QueryEntities.model_validate_json(json_string)  # Use model_validate_json\n",
        "\n",
        "                  if self.debug:\n",
        "                      rich_print(f\"‚úÖ [bold yellow]Query Analyzed. Topics:[/bold yellow] {entities.research_topics}\")\n",
        "\n",
        "                  return {\"status\": \"success\", \"entities\": entities.model_dump()}\n",
        "                except Exception as e:\n",
        "                  rich_print(f\"üí• [bold red]Error after Regex:[/bold red] {e}\")\n",
        "                  return {\"status\": \"error\", \"entities\": {\"research_topics\": [query], \"main_subject\": \"general analysis\"}}\n",
        "\n",
        "\n",
        "            else:\n",
        "                rich_print(f\"üí• [bold red]No JSON found in LLM output.[/bold red]\")\n",
        "                return {\"status\": \"error\", \"entities\": {\"research_topics\": [query], \"main_subject\": \"general analysis\"}}\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            rich_print(f\"üí• [bold red]Error in Query Analysis:[/bold red] {e}\")\n",
        "            # Fallback with a generic topic list\n",
        "            return {\"status\": \"error\", \"entities\": {\"research_topics\": [query], \"main_subject\": \"general analysis\"}}"
      ],
      "metadata": {
        "id": "wSunM9sMtAPF"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SearchResult(BaseModel):\n",
        "    topic: str\n",
        "    summary: str\n",
        "    sources: List[Dict[str, str]]\n",
        "\n",
        "class DataGatherAgent(BaseModel):\n",
        "    client: Any\n",
        "    model_name: str\n",
        "    debug: bool = False\n",
        "\n",
        "    class Config:\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "    async def _search_topic(self, topic: str) -> SearchResult:\n",
        "        \"\"\"Performs a grounded search for a single topic.\"\"\"\n",
        "        if self.debug:\n",
        "            rich_print(f\"üåê [bold blue]Data Gathering:[/bold blue] Searching for '{topic}'...\")\n",
        "\n",
        "        prompt = f\"Provide a detailed summary of the topic: {topic}. Include key technical details, recent developments, and comparisons where relevant. Base your answer entirely on the provided search results. Provide the original uri for the reference\"\n",
        "\n",
        "        try:\n",
        "            search_tool = types.Tool(\n",
        "                  google_search=types.GoogleSearch()\n",
        "            )\n",
        "\n",
        "            # Configure generation settings\n",
        "            config = types.GenerateContentConfig(\n",
        "              tools=[search_tool]\n",
        "            )\n",
        "\n",
        "\n",
        "            response = await self.client.aio.models.generate_content(\n",
        "                model=self.model_name,\n",
        "               contents=prompt,\n",
        "                config=config\n",
        "            )\n",
        "\n",
        "            supports = response.candidates[0].grounding_metadata.grounding_supports\n",
        "            chunks = response.candidates[0].grounding_metadata.grounding_chunks\n",
        "\n",
        "            sources = []\n",
        "            if hasattr(response.candidates[0], 'grounding_metadata') and response.candidates[0].grounding_metadata and hasattr(response.candidates[0].grounding_metadata, 'grounding_chunks'):\n",
        "                for chunk in response.candidates[0].grounding_metadata.grounding_chunks:\n",
        "                    if hasattr(chunk, 'web') and hasattr(chunk.web, 'uri') and hasattr(chunk.web, 'title'):\n",
        "                        sources.append({\"uri\": chunk.web.uri, \"title\": chunk.web.title})\n",
        "\n",
        "\n",
        "            summary = response.text\n",
        "            if self.debug:\n",
        "                rich_print(f\"‚úÖ [bold blue]Found {len(sources)} sources for '{topic}'.[/bold blue]\")\n",
        "\n",
        "            return SearchResult(topic=topic, summary=summary, sources=sources)\n",
        "\n",
        "        except Exception as e:\n",
        "            rich_print(f\"üí• [bold red]Search failed for topic '{topic}':[/bold red] {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return SearchResult(topic=topic, summary=f\"Failed to retrieve information for this topic.\", sources=[])\n",
        "\n",
        "    async def search(self, topics: List[str]) -> List[SearchResult]:\n",
        "        \"\"\"Concurrently searches for multiple topics.\"\"\"\n",
        "        tasks = [self._search_topic(topic) for topic in topics]\n",
        "        results = await asyncio.gather(*tasks)\n",
        "        return [result.model_dump() for result in results]\n"
      ],
      "metadata": {
        "id": "XoBcpHoGtJDw"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Report(BaseModel):\n",
        "    title: str\n",
        "    executive_summary: str\n",
        "    sections: Dict[str, str]\n",
        "    citations: List[Dict[str, str]]\n",
        "    full_report_markdown: str\n",
        "\n",
        "class ReportAgent(BaseModel):\n",
        "    client: Any\n",
        "    model_name: str\n",
        "    debug: bool = False\n",
        "\n",
        "    class Config:\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "    async def generate_report(self, query: str, search_results: List[Dict]) -> Report:\n",
        "        \"\"\"Generates a comprehensive report from search results.\"\"\"\n",
        "        if self.debug:\n",
        "            rich_print(\"‚úçÔ∏è [bold magenta]Report Generation Phase:[/bold magenta] Synthesizing search results...\")\n",
        "\n",
        "        # Prepare the context for the LLM\n",
        "        context = \"SEARCH RESULTS:\\n\\n\"\n",
        "        citations = []\n",
        "        citation_map = {}\n",
        "        for i, result in enumerate(search_results):\n",
        "            context += f\"--- Source Group {i+1} (Topic: {result['topic']}) ---\\n\"\n",
        "            context += f\"Summary: {result['summary']}\\n\"\n",
        "            context += \"Referenced Documents:\\n\"\n",
        "            for source in result['sources']:\n",
        "                if source['uri'] not in citation_map:\n",
        "                    citation_index = len(citations) + 1\n",
        "                    citations.append({\"index\": str(citation_index), \"title\": source['title'], \"uri\": source['uri']})\n",
        "                    citation_map[source['uri']] = citation_index\n",
        "                else:\n",
        "                    citation_index = citation_map[source['uri']]\n",
        "                context += f\"- [{citation_index}] {source['title']} ({source['uri']})\\n\"\n",
        "            context += \"\\n\"\n",
        "\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        You are a world-class technical and research analyst specializing in avionics, aerospace industry, .\n",
        "        Your task is to write a detailed competitive analysis report based *only* on the provided search results.\n",
        "\n",
        "        **User's Original Request:** \"{query}\"\n",
        "\n",
        "        **Your Task:**\n",
        "            1.  Write a comprehensive report that addresses the user's request.\n",
        "            2.  Structure the report with a title, an executive summary, and multiple detailed sections (e.g.,\n",
        "                \"Introduction\",\n",
        "                \"Technology Landscape Overview\",\n",
        "                \"Research Papers in this Area\",\n",
        "                \"Emerging and Macro Trends\",\n",
        "                \"Market Trends and Benchmarking\",\n",
        "                \"Competitive Landscape and Offerings\",\n",
        "                \"Key Challenges\",\n",
        "                \"Existing products in the market\",\n",
        "                \"Competitive Differentiators\",\n",
        "                \"Strategic Recommendations for Staying Ahead\",\n",
        "                \"Conclusion and Future Outlook\").\n",
        "            3.  **Crucially, you must cite every claim you make.** Use the citation numbers provided in the search results (e.g., [1], [2], etc.).\n",
        "            4.  Do not invent any information. All analysis must be directly supported by the provided context.\n",
        "            5.  The tone should be professional, objective, and technical.\n",
        "            6.  Restrict all the analysis to Avionics and Aerospace industry *only*.\n",
        "            7.  Report format should be a valid JSON string with required escape encoding\n",
        "\n",
        "\n",
        "            **Specifically for your analysis, you must:**\n",
        "            -   **Understand Competitors:** Detail what key competitors do and what their specific product offerings are in the market.\n",
        "            -   **Understand Market:** Analyze the current trends in the market and benchmark against the identified competitors.\n",
        "            -   **Bullet out the Differences:** Clearly articulate the differences between technologies, products, or approaches in a concise, bulleted format.\n",
        "            -   **Strategize to Stay Ahead:** Provide actionable strategies and recommendations to maintain a competitive edge.\n",
        "\n",
        "\n",
        "        **Provided Context (Search Results):**\n",
        "        {context}\n",
        "\n",
        "        **Output Format:**\n",
        "        Provide your response as a single, valid JSON object with the following keys:\n",
        "        - \"title\": A string for the report title.\n",
        "        - \"executive_summary\": A string for the summary.\n",
        "        - \"sections\": A valid JSON object where each key is a section title (string) and the value is the section's content (string in Markdown format).\n",
        "        \"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.client.models.generate_content(\n",
        "                model=self.model_name,\n",
        "                contents=prompt,\n",
        "            )\n",
        "            llm_output = response.text #get the response from the model.\n",
        "            print (llm_output) #For debugging\n",
        "\n",
        "            # 1. Remove Known Prefixes\n",
        "            llm_output = llm_output.replace(\"Here's the JSON:\", \"\").strip()\n",
        "            llm_output = llm_output.replace(\"Okay, I will provide the results in JSON format:\", \"\").strip()\n",
        "            llm_output = llm_output.replace(\"As requested, here's the report in JSON format:\", \"\").strip()\n",
        "\n",
        "\n",
        "            # 2. Extract JSON with more lenient regex:\n",
        "            match = re.search(r\"\\{[\\s\\S]*\\}\", llm_output)\n",
        "\n",
        "            if match:\n",
        "                json_string = match.group(0)\n",
        "\n",
        "                try:\n",
        "                   report_data = json.loads(json_string) #parse the JSON\n",
        "\n",
        "                   # Assemble the full markdown report\n",
        "                   full_markdown = f\"# {report_data['title']}\\n\\n\"\n",
        "                   full_markdown += f\"## Executive Summary\\n\\n{report_data['executive_summary']}\\n\\n\"\n",
        "                   for title, content in report_data['sections'].items():\n",
        "                       full_markdown += f\"## {title}\\n\\n{content}\\n\\n\"\n",
        "\n",
        "                   full_markdown += \"## Sources\\n\\n\"\n",
        "                   for cit in sorted(citations, key=lambda x: x['index']):\n",
        "                       full_markdown += f\"[{cit['index']}] {cit['title']}: {cit['uri']}\\n\"\n",
        "\n",
        "                   report_data['full_report_markdown'] = full_markdown\n",
        "                   report_data['citations'] = citations\n",
        "\n",
        "                   final_report = Report.model_validate(report_data)\n",
        "\n",
        "                   if self.debug:\n",
        "                       rich_print(\"‚úÖ [bold magenta]Report Generated Successfully.[/bold magenta]\")\n",
        "\n",
        "                   return final_report.model_dump()\n",
        "\n",
        "                except json.JSONDecodeError as e:\n",
        "                  rich_print(f\"üí• [bold red]Error Decoding JSON:[/bold red] {e}\")\n",
        "                  #Attempt to return some sort of report with an error message if unable to extract json\n",
        "                  return {\"title\": \"Report generation failure\", \"executive_summary\": \"Report generation failure due to llm json error, check console output\", \"sections\": {}, \"citations\": [], \"full_report_markdown\": \"\",\"error\" : str(e)} #return the report\n",
        "                except Exception as e:\n",
        "                  rich_print(f\"üí• [bold red]Error processing the report:[/bold red] {e}\")\n",
        "                  return {\"title\": \"Report generation failure\", \"executive_summary\": \"Report generation failure due to other llm error, check console output\", \"sections\": {}, \"citations\": [], \"full_report_markdown\": \"\",\"error\" : str(e)} #return the report\n",
        "\n",
        "            else:\n",
        "              rich_print(f\"üí• [bold red]No JSON found in LLM output.[/bold red]\")\n",
        "              return {\"title\": \"Report generation failure\", \"executive_summary\": \"Report generation failure due to no json found in llm output, check console output\", \"sections\": {}, \"citations\": [], \"full_report_markdown\": \"\",\"error\" : \"no json found in output\"} #return the report\n",
        "\n",
        "        except Exception as e:\n",
        "            rich_print(f\"üí• [bold red]Error during report generation:[/bold red] {e}\")\n",
        "            raise\n"
      ],
      "metadata": {
        "id": "SFUHn1zXtPEA"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExecutionAgent(BaseModel):\n",
        "    client: Any\n",
        "    model_name: str\n",
        "    debug: bool = False\n",
        "    stage_output: bool = False\n",
        "\n",
        "    class Config:\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "    async def execute(self, query: str) -> Optional[Dict]:\n",
        "        \"\"\"Executes the full analysis pipeline for 3GPP research.\"\"\"\n",
        "        try:\n",
        "            rich_print(f\"‚ñ∂Ô∏è [bold green]Starting Execution for query:[/bold green] '{query}'\")\n",
        "\n",
        "            # 1. Planning Phase\n",
        "            planning_agent = PlanningAgent(\n",
        "                client=self.client,\n",
        "                model_name=self.model_name,\n",
        "                debug=self.debug\n",
        "            )\n",
        "            plan = planning_agent.create_plan(query)\n",
        "            if self.stage_output: rich_print(plan)\n",
        "\n",
        "            # 2. Query Analysis\n",
        "            query_agent = QueryAnalysisAgent(\n",
        "                client=self.client,\n",
        "                model_name=self.model_name,\n",
        "                debug=self.debug\n",
        "            )\n",
        "            analyzed_query = query_agent.analyze(query)\n",
        "            if self.stage_output: rich_print(analyzed_query)\n",
        "\n",
        "            # 3. Data Gathering (via Web Search)\n",
        "            data_agent = DataGatherAgent(\n",
        "                client=self.client,\n",
        "                model_name=self.model_name,\n",
        "                debug=self.debug\n",
        "            )\n",
        "            gathered_data = await data_agent.search(\n",
        "                topics=analyzed_query['entities']['research_topics']\n",
        "            )\n",
        "            if self.stage_output: rich_print(gathered_data)\n",
        "\n",
        "            # 4. Report Generation\n",
        "            report_agent = ReportAgent(\n",
        "                client=self.client,\n",
        "                model_name=self.model_name,\n",
        "                debug=self.debug\n",
        "            )\n",
        "            report = await report_agent.generate_report(\n",
        "                query=query,\n",
        "                search_results=gathered_data\n",
        "            )\n",
        "            if self.stage_output: rich_print(report)\n",
        "\n",
        "            return {\"report\": report}\n",
        "\n",
        "        except Exception as e:\n",
        "            rich_print(f\"üí• [bold red]Error during execution:[/bold red] {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "\n",
        "    @classmethod\n",
        "    def create(cls, client: Any, model_name: str, debug: bool = False, stage_output: bool = False) -> \"ExecutionAgent\":\n",
        "        return cls(\n",
        "            client=client,\n",
        "            model_name=model_name,\n",
        "            debug=debug,\n",
        "            stage_output=stage_output\n",
        "        )"
      ],
      "metadata": {
        "id": "KYrM2B7dsV6x"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_filename(\n",
        "    user_input: str,\n",
        "    extension: str,\n",
        "    add_timestamp: bool = True,\n",
        "    max_length: int = 60,\n",
        "    default_name: str = \"document\"\n",
        ") -> str:\n",
        "    \"\"\"\n",
        "    Generates a robust, safe, and unique filename from user input.\n",
        "\n",
        "    - Handles empty or whitespace-only input.\n",
        "    - Converts to lowercase.\n",
        "    - Replaces spaces and invalid characters with hyphens (a \"slugify\" approach).\n",
        "    - Truncates the name to a safe length.\n",
        "    - Optionally adds a timestamp to ensure uniqueness.\n",
        "\n",
        "    Args:\n",
        "        user_input: The string to convert into a filename.\n",
        "        extension: The file extension (e.g., \"txt\", \"md\").\n",
        "        add_timestamp: If True, appends a YYYYMMDD-HHMMSS timestamp.\n",
        "        max_length: The maximum character length for the base name part.\n",
        "        default_name: The name to use if user_input is empty.\n",
        "\n",
        "    Returns:\n",
        "        A robust, safe, and unique filename string.\n",
        "    \"\"\"\n",
        "    # 1. Handle empty or whitespace-only input\n",
        "    base_name = user_input.strip()\n",
        "    if not base_name:\n",
        "        base_name = default_name\n",
        "\n",
        "    # 2. Convert to lowercase and \"slugify\"\n",
        "    # Replace any character that is not a letter, number, or whitespace with a space\n",
        "    base_name = re.sub(r'[^\\w\\s-]', ' ', base_name.lower())\n",
        "    # Replace one or more whitespace characters or hyphens with a single hyphen\n",
        "    base_name = re.sub(r'[\\s-]+', '-', base_name).strip('-')\n",
        "\n",
        "    # 3. Truncate to a max length\n",
        "    base_name = base_name[:max_length].strip('-')\n",
        "\n",
        "    # 4. Get timestamp if requested\n",
        "    timestamp_str = \"\"\n",
        "    if add_timestamp:\n",
        "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        timestamp_str = f\"_{timestamp}\"\n",
        "\n",
        "    # 5. Clean up extension and assemble the final name\n",
        "    clean_extension = extension.lstrip('.')\n",
        "\n",
        "    return f\"{base_name}{timestamp_str}.{clean_extension}\"\n"
      ],
      "metadata": {
        "id": "8Ep7QwA5gwXz"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    def save_as_docx_1(markdown_string: str, filename: str):\n",
        "        \"\"\"Converts Markdown string to DOCX and saves it using python-docx.\"\"\"\n",
        "        try:\n",
        "            from docx import Document\n",
        "            from docx.shared import Inches\n",
        "        except ImportError:\n",
        "            rich_print(\"   [red]Skipping DOCX generation: python-docx library not installed.[/red]\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            doc = Document()\n",
        "            lines = markdown_string.split('\\n')\n",
        "            current_paragraph = None\n",
        "\n",
        "            for line in lines:\n",
        "                if line.startswith('# '):\n",
        "                    if current_paragraph: doc.add_paragraph()\n",
        "                    p = doc.add_paragraph()\n",
        "                    p.add_run(line[2:]).bold = True\n",
        "                    p.add_run(\" (Heading 1)\").italic = True\n",
        "                elif line.startswith('## '):\n",
        "                    if current_paragraph: doc.add_paragraph()\n",
        "                    p = doc.add_paragraph()\n",
        "                    p.add_run(line[3:]).bold = True\n",
        "                    p.add_run(\" (Heading 2)\").italic = True\n",
        "                elif line.startswith('- ['):\n",
        "                    match = re.match(r'- \\[(.*?)\\] (.*?)\\((.*?)\\)', line)\n",
        "                    if match:\n",
        "                        index, title, uri = match.groups()\n",
        "                        if current_paragraph: doc.add_paragraph()\n",
        "                        p = doc.add_paragraph()\n",
        "                        p.add_run(f\"[{index}] \").italic = True\n",
        "                        p.add_run(f\"{title}: {uri}\").italic = True\n",
        "                    else:\n",
        "                        if current_paragraph: doc.add_paragraph()\n",
        "                        p = doc.add_paragraph(line)\n",
        "                elif line.strip() == \"\":\n",
        "                    if current_paragraph: doc.add_paragraph()\n",
        "                else:\n",
        "                    if current_paragraph is None or current_paragraph.text.strip() != \"\":\n",
        "                         p = doc.add_paragraph()\n",
        "                         run = p.add_run(line)\n",
        "                         current_paragraph = p\n",
        "                    else:\n",
        "                        current_paragraph.add_run(\" \" + line)\n",
        "\n",
        "            doc.save(filename)\n",
        "            rich_print(f\"   [green]Successfully saved DOCX: {filename}[/green]\")\n",
        "            return filename\n",
        "        except Exception as e:\n",
        "            rich_print(f\"   [red]Error saving DOCX file:[/red] {e}\")\n",
        "            return None\n"
      ],
      "metadata": {
        "id": "mfHVNYloko16"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_as_docx(markdown_string: str, filename: str):\n",
        "    \"\"\"Converts Markdown string to DOCX using pypandoc for proper formatting.\"\"\"\n",
        "    if pypandoc is None:\n",
        "        rich_print(\"   [red]Skipping DOCX generation: pypandoc library not installed or pandoc not found.[/red]\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        pypandoc.convert_text(\n",
        "            markdown_string,\n",
        "            'docx',          # Output format\n",
        "            format='md',     # Input format\n",
        "            outputfile=filename,\n",
        "        )\n",
        "        rich_print(f\"   [green]Successfully saved DOCX: {filename}[/green]\")\n",
        "        return filename\n",
        "    except Exception as e:\n",
        "        rich_print(f\"   [red]Error saving DOCX file with pypandoc:[/red] {e}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "NxIj_cZNq44v"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def main(model, query):\n",
        "    \"\"\"The main function to run the agentic workflow.\"\"\"\n",
        "    # MODEL_NAME = \"gemini-2.5-flash\"\n",
        "    # USER_QUERY = \"3GPP 5G and 6G integration for aviation, specifically for aircraft routers.\"\n",
        "    MODEL_NAME=model\n",
        "    USER_QUERY=query\n",
        "\n",
        "    display(Markdown(f\"## üöÄ Kicking off research for: '{USER_QUERY}'\"))\n",
        "\n",
        "    try:\n",
        "        client = genai.Client(api_key=\"AIzaSyBKYSHvUDhD2tcKgPxMJYkNuUhZp8qSOrc\")\n",
        "        agent = ExecutionAgent.create(\n",
        "            client=client,\n",
        "            model_name=MODEL_NAME,\n",
        "            debug=True,\n",
        "            stage_output=False\n",
        "        )\n",
        "        result = await agent.execute(query=USER_QUERY)\n",
        "\n",
        "        file_name=generate_filename(query, \"docx\",True,40,\"Untitled\")\n",
        "        display(Markdown(\"--- \\n ## üìÑ Final Report\"))\n",
        "        if result and result.get(\"report\"):\n",
        "            final_report=result[\"report\"][\"full_report_markdown\"]\n",
        "            doc_file_name=save_as_docx(final_report,file_name)\n",
        "\n",
        "            files.download(doc_file_name)\n",
        "\n",
        "            display(Markdown(final_report))\n",
        "        else:\n",
        "            display(Markdown(\"### ‚ùå Report generation failed. Please check the logs above for errors.\"))\n",
        "\n",
        "    except Exception as e:\n",
        "        rich_print(f\"üí• [bold red]A critical error occurred in the main execution block:[/bold red] {e}\")\n",
        "        traceback.print_exc()\n",
        "\n"
      ],
      "metadata": {
        "id": "SCVLVdgitTHg"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    user_query_from_user = input(\"Enter your query for the report: \").strip()\n",
        "    if not user_query_from_user:\n",
        "        user_query_from_user = \"Provide the competitive analysis of avionics router for cabin\"\n",
        "\n",
        "    try:\n",
        "        await main(\"gemini-2.5-flash\", user_query_from_user)\n",
        "\n",
        "    except NameError:\n",
        "        print(\"\\n--- Failed to perform the requested operation ---\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nFnlPtMiti2h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}